# Phase 4 Specification
## Local Kubernetes Deployment of Todo AI Chatbot

**Version:** v1.0
**Date:** 2026-02-08
**Based on:** constitution.md v4.0

## Objective
Deploy the Phase 3 Todo AI Chatbot (FastAPI backend + OpenAI ChatKit frontend) on local Minikube as a stateless, resilient, observable cloud-native application using Helm and AI-assisted tools.

## Scope & Assumptions
- Reuse Phase 3 code without changes (backend: FastAPI + Agents SDK + MCP, frontend: ChatKit)
- Local only (Minikube, no cloud provider)
- Database: use env var for Neon URL or local Postgres pod if needed
- Authentication: Better Auth from Phase 3
- No manual editing of generated files (Dockerfiles, YAMLs, etc.)

## Functional Requirements
- Containerize both backend and frontend (Dockerfiles generated by docker-engineer)
- Package as Helm charts (generated by helm-chart-engineer)
- Deploy to Minikube (using minikube-deployer)
- Expose services locally via port-forward
- Verify todo management via chat UI (add, list, complete, update, delete)
- Support environment-specific configurations via Helm values

## Non-Functional Requirements
- Stateless: no in-memory state, all in DB
- Resilient: liveness/readiness probes, replicas ≥ 2, auto-restart
- Observable: pod logs, events, kubectl-ai/kagent health checks, minikube dashboard
- Scalable locally: support horizontal scaling (kubectl scale)
- Secure: env vars for keys, no root containers
- Performance: sub-second response times under normal load
- Maintainability: clear separation of concerns in generated artifacts

## Architecture Overview

```
Minikube Cluster
├── Deployment: todo-backend (2 replicas, port 8000)
│   ├── Service: ClusterIP
│   ├── ConfigMap: app-config
│   ├── Secret: app-secrets
│   └── Env: OPENAI_API_KEY, DATABASE_URL
├── Deployment: todo-frontend (2 replicas, port 3000)
│   ├── Service: ClusterIP
│   ├── ConfigMap: frontend-config
│   └── Env: NEXT_PUBLIC_OPENAI_DOMAIN_KEY
└── Tools: Gordon, kubectl-ai, kagent for ops
```

### Component Details:
- **todo-backend**: FastAPI application with Agents SDK and MCP integration
- **todo-frontend**: Next.js ChatKit UI with Better Auth integration
- **Database**: External Neon PostgreSQL or internal Postgres pod
- **Services**: Internal ClusterIP services, exposed via port-forward

## Tools & Agents Mapping

| Agent | Responsibility | Output |
|-------|---------------|---------|
| docker-engineer | Dockerfiles & build commands | Dockerfile, docker-compose.yml |
| helm-chart-engineer | Helm charts & values | charts/todo-backend/, charts/todo-frontend/ |
| minikube-deployer | Minikube operations & deployment | Deployed cluster resources |
| aiops-troubleshooter | Debugging & fixes | Troubleshooting guide & fixes |
| infra-spec-writer | Infrastructure blueprint | Infrastructure documentation |
| deployment-tester | Post-deploy validation | Health check results |

## Technical Specifications

### Backend Deployment
- Image: todo-backend:latest (built from backend/)
- Ports: 8000
- Environment Variables:
  - OPENAI_API_KEY
  - DATABASE_URL
  - BETTER_AUTH_SECRET
  - BETTER_AUTH_URL
- Resources: requests/limits for CPU/Memory
- Probes: Liveness and readiness on /health

### Frontend Deployment
- Image: todo-frontend:latest (built from frontend/)
- Ports: 3000
- Environment Variables:
  - NEXT_PUBLIC_OPENAI_DOMAIN_KEY
  - NEXT_PUBLIC_BACKEND_URL
- Resources: requests/limits for CPU/Memory
- Probes: Liveness and readiness on /

## Deployment Steps
1. Start Minikube cluster
2. Build Docker images for backend and frontend
3. Create Helm chart templates
4. Install Helm charts with configured values
5. Verify deployments and services
6. Set up port-forwarding for local access

## Risks & Mitigations

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Image pull fail | High | Low | Pre-pull images, use minikube cache, check docker images |
| Port conflict | Medium | Medium | Use dynamic port selection, check available ports |
| Pod crash | High | Medium | Implement proper health checks, use aiops-troubleshooter |
| Resource exhaustion | High | Low | Set resource limits, monitor resource usage |
| Network connectivity | Medium | Low | Verify service networking, check ingress if needed |

## Timeline & Task Breakdown

| Step | Task | Estimated Time | Dependencies |
|------|------|----------------|--------------|
| 1 | Containerization (Dockerfiles) | 30 min | Phase 3 codebase |
| 2 | Helm Chart Generation | 30 min | Containerized images |
| 3 | Minikube Setup & Deployment | 20 min | Helm charts ready |
| 4 | Service Configuration & Port-forward | 15 min | Deployments running |
| 5 | Testing & Validation | 20 min | Services accessible |
| 6 | Troubleshooting & Optimization | 20 min | Initial deployment complete |
| **Total** | | **~2.3 hours** | |

## Acceptance Criteria

### Minikube Setup
- [ ] Minikube cluster started successfully
- [ ] kubectl connected to cluster
- [ ] Docker images built and available

### Deployment Validation
- [ ] Helm charts install without errors
- [ ] Both backend and frontend pods Running/Ready
- [ ] All replicas (≥2) available
- [ ] Services accessible within cluster

### Functional Validation
- [ ] Backend API responds on localhost:8000
- [ ] Frontend Chat UI loads on localhost:3000
- [ ] Todo commands (add/list/complete) work via chat
- [ ] Better Auth integration functional
- [ ] Database connections established

### Observability & Resilience
- [ ] Liveness/readiness probes configured and passing
- [ ] Pod logs accessible via kubectl logs
- [ ] Auto-restart configured for failed pods
- [ ] Horizontal scaling possible via kubectl scale

### Documentation & Cleanup
- [ ] All generated files documented
- [ ] Troubleshooting guide available
- [ ] Deployment steps recorded in README
- [ ] Clean shutdown procedures defined
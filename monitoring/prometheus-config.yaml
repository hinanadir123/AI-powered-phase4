apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-server-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    rule_files:
      - "/etc/prometheus/rules/*.rules"

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    scrape_configs:
      # Scrape Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      # Scrape kube-state-metrics
      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics:8080']

      # Scrape node-exporter
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__address__]
            regex: '(.*):10250'
            target_label: __address__
            replacement: '${1}:9100'

      # Scrape kubernetes components
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

      # Scrape all pods that expose metrics
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
        metric_relabel_configs:
          - source_labels: [__name__]
            regex: 'go_.*'
            action: drop
          - source_labels: [__name__]
            regex: 'process_.*'
            action: drop

      # Scrape Dapr sidecars
      - job_name: 'dapr-sidecars'
        scrape_interval: 5s
        scrape_timeout: 4s
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - default
                - production
        relabel_configs:
          # Only scrape pods with Dapr annotations
          - source_labels: [__meta_kubernetes_pod_annotation_dapr_io_app_id]
            action: keep
            regex: .+
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__address__]
            target_label: __address__
            regex: ([^:]+)(?::\d+)?
            replacement: ${1}:9090
          - source_labels: [__meta_kubernetes_pod_annotation_dapr_io_app_id]
            target_label: dapr_app_id

      # Scrape backend service
      - job_name: 'todo-backend'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: 'todo-backend'
          - source_labels: [__address__]
            regex: ([^:]+)(?::\d+)?
            replacement: ${1}:8000
            target_label: __address__
          - target_label: job
            replacement: todo-backend

      # Scrape frontend service
      - job_name: 'todo-frontend'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: 'todo-frontend'
          - source_labels: [__address__]
            regex: ([^:]+)(?::\d+)?
            replacement: ${1}:3000
            target_label: __address__
          - target_label: job
            replacement: todo-frontend

      # Scrape reminder worker
      - job_name: 'reminder-worker'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: 'reminder-worker'
          - source_labels: [__address__]
            regex: ([^:]+)(?::\d+)?
            replacement: ${1}:8001
            target_label: __address__
          - target_label: job
            replacement: reminder-worker

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  alerts.rules: |
    groups:
      - name: application_alerts
        rules:
          - alert: HighErrorRate
            expr: sum(rate(http_requests_total{status=~"5..|4.."}[5m])) / sum(rate(http_requests_total[5m])) > 0.05
            for: 5m
            labels:
              severity: warning
              category: application
            annotations:
              summary: "High error rate on {{ $labels.job }}"
              description: "Error rate is {{ $value }} for {{ $labels.job }}"

          - alert: HighRequestLatency
            expr: histogram_quantile(0.95, sum by(le, job)(rate(http_request_duration_seconds_bucket[5m]))) > 1
            for: 5m
            labels:
              severity: warning
              category: application
            annotations:
              summary: "High latency for {{ $labels.job }}"
              description: "{{ $labels.job }} is experiencing high request latency (p95 > 1s): {{ $value }}s"

          - alert: LowRequestRate
            expr: sum(rate(http_requests_total[2m])) < 1
            for: 5m
            labels:
              severity: critical
              category: application
            annotations:
              summary: "No traffic to application"
              description: "No HTTP requests in the last 2 minutes, possibly down"

      - name: infrastructure_alerts
        rules:
          - alert: HighCPUUsage
            expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
            for: 10m
            labels:
              severity: warning
              category: infrastructure
            annotations:
              summary: "High CPU usage on {{ $labels.instance }}"
              description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

          - alert: HighMemoryUsage
            expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 90
            for: 5m
            labels:
              severity: warning
              category: infrastructure
            annotations:
              summary: "High memory usage on {{ $labels.instance }}"
              description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
            for: 5m
            labels:
              severity: warning
              category: infrastructure
            annotations:
              summary: "Pod {{ $labels.pod }} has been restarted"
              description: "Pod {{ $labels.pod }} has been restarted {{ $value }} times in the last 15 minutes"

          - alert: PodNotReady
            expr: sum by(namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"}) > 0
            for: 5m
            labels:
              severity: critical
              category: infrastructure
            annotations:
              summary: "Pod {{ $labels.pod }} is not ready"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is in {{ $labels.phase }} state for more than 5 minutes"

      - name: kafka_alerts
        rules:
          - alert: KafkaHighConsumerLag
            expr: kafka_consumer_lag > 1000
            for: 5m
            labels:
              severity: warning
              category: kafka
            annotations:
              summary: "High consumer lag for partition {{ $labels.partition }}"
              description: "Consumer lag is {{ $value }} messages for {{ $labels.topic }}-{{ $labels.partition }}"

          - alert: KafkaClusterDown
            expr: kafka_broker_info == 0
            for: 3m
            labels:
              severity: critical
              category: kafka
            annotations:
              summary: "Kafka cluster is down"
              description: "Kafka cluster appears to be down, no brokers are available"

          - alert: KafkaHighUnderReplicatedPartitions
            expr: kafka_server_replicamanager_underreplicatedpartitions > 0
            for: 1m
            labels:
              severity: critical
              category: kafka
            annotations:
              summary: "Kafka has under-replicated partitions"
              description: "There are {{ $value }} under-replicated partitions in the Kafka cluster"

      - name: dapr_alerts
        rules:
          - alert: DaprSidecarDown
            expr: up{__name__="up", job="dapr-sidecars"} == 0
            for: 2m
            labels:
              severity: critical
              category: dapr
            annotations:
              summary: "Dapr sidecar down"
              description: "Dapr sidecar for app {{ $labels.dapr_app_id }} is not responding"

          - alert: HighDaprAPILatency
            expr: histogram_quantile(0.95, sum by(dapr_app_id, le)(rate(dapr_http_client_req_lat_bucket[5m]))) > 1
            for: 5m
            labels:
              severity: warning
              category: dapr
            annotations:
              summary: "High Dapr API latency for {{ $labels.dapr_app_id }}"
              description: "P95 latency for Dapr API calls to {{ $labels.dapr_app_id }} is {{ $value }}s"
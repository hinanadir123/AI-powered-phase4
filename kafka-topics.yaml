# Kafka Topics Configuration for Todo AI Chatbot - Phase 5
# Task: T5.1.1 - Generate Kafka Topics Configuration
# Spec Reference: phase5-spec.md Section 3 (Event-Driven Architecture)
# Constitution: constitution.md v5.0 Section 2.3 (Event-Driven Architecture Requirements)
#
# This file defines all Kafka topics for the event-driven architecture.
# Topics are used for async operations: task events, reminders, and real-time updates.
#
# Version: 1.0
# Date: 2026-02-15
# Generated by: kafka-dapr-engineer agent

---
# Topic Configuration Standards
# - Partitions: 3 (for parallel processing and scalability)
# - Replication Factor: 3 (for high availability and fault tolerance)
# - Retention: 7 days (168 hours) for main topics, 30 days for DLQ
# - Cleanup Policy: delete (time-based retention)
# - Compression: snappy (balance between compression ratio and CPU usage)

topics:
  # ============================================================================
  # Main Topic: task-events
  # Purpose: Task CRUD operations (created, updated, deleted, completed)
  # Publishers: Backend API
  # Subscribers: Reminder Worker, Analytics Service (future)
  # ============================================================================
  - name: task-events
    partitions: 3
    replication_factor: 3
    config:
      retention.ms: 604800000  # 7 days in milliseconds
      cleanup.policy: delete
      compression.type: snappy
      min.insync.replicas: 2  # Ensure at least 2 replicas acknowledge writes
      max.message.bytes: 1048576  # 1MB max message size
      segment.ms: 86400000  # Roll segment every 24 hours
    description: |
      Task lifecycle events including creation, updates, deletion, and completion.
      Event types: task.created, task.updated, task.deleted, task.completed
      Schema: CloudEvents format with task payload

  # ============================================================================
  # Main Topic: reminders
  # Purpose: Reminder scheduling and notification events
  # Publishers: Reminder Worker, Backend API
  # Subscribers: Notification Service, Frontend Sync Service
  # ============================================================================
  - name: reminders
    partitions: 3
    replication_factor: 3
    config:
      retention.ms: 604800000  # 7 days
      cleanup.policy: delete
      compression.type: snappy
      min.insync.replicas: 2
      max.message.bytes: 1048576  # 1MB
      segment.ms: 86400000  # 24 hours
    description: |
      Reminder scheduling and triggered notification events.
      Event types: reminder.scheduled, reminder.triggered
      Schema: CloudEvents format with reminder payload

  # ============================================================================
  # Main Topic: task-updates
  # Purpose: Real-time task updates for frontend synchronization
  # Publishers: Backend API
  # Subscribers: Frontend Sync Service, WebSocket Gateway
  # ============================================================================
  - name: task-updates
    partitions: 3
    replication_factor: 3
    config:
      retention.ms: 86400000  # 1 day (shorter retention for real-time updates)
      cleanup.policy: delete
      compression.type: snappy
      min.insync.replicas: 2
      max.message.bytes: 524288  # 512KB (smaller messages for real-time)
      segment.ms: 3600000  # Roll segment every 1 hour
    description: |
      Real-time task synchronization events for frontend updates.
      Event types: task.sync
      Schema: CloudEvents format with minimal task payload

  # ============================================================================
  # Dead Letter Queue: task-events-dlq
  # Purpose: Failed task event processing
  # Publishers: Reminder Worker (on processing failure)
  # Subscribers: Error Monitoring Service, Manual Review
  # ============================================================================
  - name: task-events-dlq
    partitions: 3
    replication_factor: 3
    config:
      retention.ms: 2592000000  # 30 days (longer retention for debugging)
      cleanup.policy: delete
      compression.type: snappy
      min.insync.replicas: 2
      max.message.bytes: 2097152  # 2MB (larger for error context)
      segment.ms: 86400000  # 24 hours
    description: |
      Dead letter queue for failed task event processing.
      Contains original event + error metadata for debugging.
      Manual intervention required for reprocessing.

  # ============================================================================
  # Dead Letter Queue: reminders-dlq
  # Purpose: Failed reminder processing
  # Publishers: Notification Service (on delivery failure)
  # Subscribers: Error Monitoring Service, Manual Review
  # ============================================================================
  - name: reminders-dlq
    partitions: 3
    replication_factor: 3
    config:
      retention.ms: 2592000000  # 30 days
      cleanup.policy: delete
      compression.type: snappy
      min.insync.replicas: 2
      max.message.bytes: 2097152  # 2MB
      segment.ms: 86400000  # 24 hours
    description: |
      Dead letter queue for failed reminder delivery.
      Contains original reminder event + error metadata.
      Retry logic should be implemented before sending to DLQ.

  # ============================================================================
  # Dead Letter Queue: task-updates-dlq
  # Purpose: Failed real-time update delivery
  # Publishers: Frontend Sync Service (on delivery failure)
  # Subscribers: Error Monitoring Service
  # ============================================================================
  - name: task-updates-dlq
    partitions: 3
    replication_factor: 3
    config:
      retention.ms: 604800000  # 7 days (shorter than other DLQs)
      cleanup.policy: delete
      compression.type: snappy
      min.insync.replicas: 2
      max.message.bytes: 1048576  # 1MB
      segment.ms: 86400000  # 24 hours
    description: |
      Dead letter queue for failed real-time update delivery.
      Less critical than other DLQs as updates are eventually consistent.

---
# Topic Creation Commands
#
# For Redpanda (Docker or Cloud):
# --------------------------------
# kafka-topics --bootstrap-server {REDPANDA_BROKER_ADDRESS} --create --topic task-events --partitions 3 --replication-factor 3 --config retention.ms=604800000 --config compression.type=snappy --config min.insync.replicas=2
# kafka-topics --bootstrap-server {REDPANDA_BROKER_ADDRESS} --create --topic reminders --partitions 3 --replication-factor 3 --config retention.ms=604800000 --config compression.type=snappy --config min.insync.replicas=2
# kafka-topics --bootstrap-server {REDPANDA_BROKER_ADDRESS} --create --topic task-updates --partitions 3 --replication-factor 3 --config retention.ms=86400000 --config compression.type=snappy --config min.insync.replicas=2
# kafka-topics --bootstrap-server {REDPANDA_BROKER_ADDRESS} --create --topic task-events-dlq --partitions 3 --replication-factor 3 --config retention.ms=2592000000 --config compression.type=snappy --config min.insync.replicas=2
# kafka-topics --bootstrap-server {REDPANDA_BROKER_ADDRESS} --create --topic reminders-dlq --partitions 3 --replication-factor 3 --config retention.ms=2592000000 --config compression.type=snappy --config min.insync.replicas=2
# kafka-topics --bootstrap-server {REDPANDA_BROKER_ADDRESS} --create --topic task-updates-dlq --partitions 3 --replication-factor 3 --config retention.ms=604800000 --config compression.type=snappy --config min.insync.replicas=2
#
# For Strimzi (Kubernetes Operator):
# -----------------------------------
# Apply KafkaTopic CRDs (see strimzi-topics.yaml for Kubernetes manifests)
#
# Verification Commands:
# ----------------------
# List all topics:
# kafka-topics --bootstrap-server {BROKER_ADDRESS} --list
#
# Describe specific topic:
# kafka-topics --bootstrap-server {BROKER_ADDRESS} --describe --topic task-events
#
# Check topic configuration:
# kafka-configs --bootstrap-server {BROKER_ADDRESS} --describe --entity-type topics --entity-name task-events

---
# Strimzi KafkaTopic CRDs (for Kubernetes deployment)
# Apply these manifests when using Strimzi operator
#
# apiVersion: kafka.strimzi.io/v1beta2
# kind: KafkaTopic
# metadata:
#   name: task-events
#   labels:
#     strimzi.io/cluster: {KAFKA_CLUSTER_NAME}
# spec:
#   partitions: 3
#   replicas: 3
#   config:
#     retention.ms: 604800000
#     compression.type: snappy
#     min.insync.replicas: 2
#     max.message.bytes: 1048576
#     segment.ms: 86400000
#
# (Repeat for all topics with appropriate configurations)

---
# Consumer Group Configuration
#
# Consumer Groups:
# - backend-group: Backend API consumers
# - worker-group: Reminder Worker consumers
# - frontend-sync-group: Frontend Sync Service consumers
# - notification-group: Notification Service consumers
#
# Consumer Group Settings:
# - auto.offset.reset: earliest (process all messages from beginning on first start)
# - enable.auto.commit: false (manual commit for exactly-once semantics)
# - max.poll.records: 100 (batch size for processing)
# - session.timeout.ms: 30000 (30 seconds)
# - heartbeat.interval.ms: 10000 (10 seconds)

---
# Partitioning Strategy
#
# Partition Key: task_id
# Rationale: Ensures all events for the same task go to the same partition,
#            maintaining event ordering per task while allowing parallel processing
#            across different tasks.
#
# Example:
# - Task ID "task-123" → Partition 0 (hash(task-123) % 3 = 0)
# - Task ID "task-456" → Partition 1 (hash(task-456) % 3 = 1)
# - Task ID "task-789" → Partition 2 (hash(task-789) % 3 = 2)

---
# Monitoring and Alerting
#
# Metrics to Monitor:
# - kafka_topic_partition_current_offset: Current offset per partition
# - kafka_topic_partition_oldest_offset: Oldest offset per partition
# - kafka_consumergroup_lag: Consumer group lag (messages behind)
# - kafka_topic_partition_replicas: Number of replicas per partition
# - kafka_topic_partition_in_sync_replicas: Number of in-sync replicas
#
# Alert Rules:
# - Consumer lag > 1000 messages for 5 minutes
# - In-sync replicas < min.insync.replicas
# - Topic partition offline
# - Message production rate drops to 0 for 10 minutes

---
# END OF KAFKA TOPICS CONFIGURATION
